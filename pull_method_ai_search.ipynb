{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search: vector search, step by step using Pull Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "blob_container_name = os.getenv(\"BLOB_CONTAINER_NAME\", \"int-vec\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "azure_openai_model_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\"))\n",
    "azure_storage_connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "azure_ai_service_key = os.getenv(\"AI_SERVICE_KEY\")\n",
    "\n",
    "azure_credential = AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index\n",
    "Configrue fields (columns), vector search, and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index-name-pull-method created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    HnswParameters\n",
    ")\n",
    "\n",
    "index_name = \"index-name-pull-method\"\n",
    "# Create a search index  \n",
    "fields = [  \n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, retrievable=True, searchable=True, sortable=True, filterable=True, facetable=True, key=True, analyzer_name='keyword'),  \n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, retrievable=True, searchable=False, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"content\", type=SearchFieldDataType.String, retrievable=True, searchable=True, index_analyzer_name=\"keyword\", search_analyzer_name=\"standard\"),  \n",
    "    SearchField(name=\"keyphrase\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), retrievable=True, searchable=True, index_analyzer_name=\"keyword\", search_analyzer_name=\"standard\"),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String, retrievable=True, filterable=True, searchable=True, index_analyzer_name=\"keyword\", search_analyzer_name=\"standard\"),  \n",
    "    SearchField(name=\"url\", type=SearchFieldDataType.String, retrievable=True, searchable=False),  \n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\", searchable=True),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\", \n",
    "                                   kind=VectorSearchAlgorithmKind.HNSW, \n",
    "                                   parameters=HnswParameters(metric=\"cosine\")),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                model_name=azure_openai_model_name,\n",
    "                deployment_id=azure_openai_model_name,\n",
    "                api_key=azure_openai_key,\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"content\")]  \n",
    "    ),  \n",
    ")\n",
    "  \n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Skillset\n",
    "A skillset is an array of one or more skills that perform an enrichment, such as translating text or optical character recognition (OCR) on an image file. Skills can be the built-in skills from Microsoft, or custom skills for processing logic that you host externally. A skillset produces enriched documents that are either consumed during indexing or projected to a knowledge store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index-name-pull-method-skillset created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey,\n",
    "    OcrSkill,\n",
    "    MergeSkill,\n",
    "    KeyPhraseExtractionSkill\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "\n",
    "ocr_skill = OcrSkill(\n",
    "    name=\"OCRSkill\",\n",
    "    description=\"Extract Text from Images\",\n",
    "    context=\"/document/normalized_images/*\",\n",
    "    default_language_code=\"en\",\n",
    "    should_detect_orientation=True,\n",
    "    inputs=[InputFieldMappingEntry(name=\"image\", source=\"/document/normalized_images/*\")],\n",
    "    outputs=[OutputFieldMappingEntry(name=\"text\", target_name=\"text\")]\n",
    ")\n",
    "\n",
    "merge_skill = MergeSkill(\n",
    "    name=\"MergeSkill\",\n",
    "    description=\"merge OCR and text\",\n",
    "    context=\"/document\",\n",
    "    inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),\n",
    "            InputFieldMappingEntry(name=\"itemsToInsert\", source=\"/document/normalized_images/*/text\"),\n",
    "            InputFieldMappingEntry(name=\"offsets\", source= \"/document/normalized_images/*/contentOffset\")],\n",
    "    outputs=[OutputFieldMappingEntry(name=\"mergedText\", target_name=\"mergedText\")]\n",
    ")\n",
    "\n",
    "split_skill = SplitSkill(\n",
    "    description=\"Split skill to chunk documents\",\n",
    "    text_split_mode=\"pages\",\n",
    "    context=\"/document\",\n",
    "    maximum_page_length=2000,\n",
    "    page_overlap_length=500,\n",
    "    default_language_code=\"id\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/mergedText\"), #missing or empty\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "key_phrase_skill = KeyPhraseExtractionSkill(\n",
    "    name=\"KeyPhraseExtractionSkill\",\n",
    "    description=\"extracting important keywords from chunks\",\n",
    "    context=\"/document/pages/*\",\n",
    "    default_language_code=\"en\",\n",
    "    max_key_phrase_count=2,\n",
    "    inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\")],\n",
    "    outputs=[OutputFieldMappingEntry(name=\"keyPhrases\", target_name=\"keyphrases\")]\n",
    ")\n",
    "\n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",\n",
    "    context=\"/document/pages/*\",\n",
    "    resource_uri=azure_openai_endpoint,\n",
    "    deployment_id=azure_openai_model_name,\n",
    "    model_name=azure_openai_model_name,\n",
    "    dimensions=azure_openai_model_dimensions,\n",
    "    api_key=azure_openai_key,\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"), #cannot iterate non array\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_projections = SearchIndexerIndexProjections(\n",
    "    selectors=[\n",
    "        SearchIndexerIndexProjectionSelector(\n",
    "            target_index_name=index_name,\n",
    "            parent_key_field_name=\"parent_id\",\n",
    "            source_context=\"/document/pages/*\",\n",
    "            mappings=[\n",
    "                InputFieldMappingEntry(name=\"content\", source=\"/document/pages/*\"),\n",
    "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/vector\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "                InputFieldMappingEntry(name=\"url\", source=\"/document/metadata_storage_path\"),\n",
    "                InputFieldMappingEntry(name=\"keyphrase\", source=\"/document/pages/*/keyphrases\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    parameters=SearchIndexerIndexProjectionsParameters(\n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
    "    ),\n",
    ")\n",
    "\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=azure_ai_service_key)\n",
    "skills = [ocr_skill, merge_skill, split_skill, key_phrase_skill, embedding_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(\n",
    "    name=skillset_name,\n",
    "    description=\"Skillset to chunk documents and generating embeddings\",\n",
    "    skills=skills,\n",
    "    index_projections=index_projections,\n",
    "    cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "\n",
    "client = SearchIndexerClient(AZURE_SEARCH_ENDPOINT, azure_credential)\n",
    "client.create_or_update_skillset(skillset)\n",
    "print(f\"{skillset.name} created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataSource\n",
    "Connect Data Source (Azure Storage Accounts) with AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'index-name-pull-method-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection\n",
    ")\n",
    "\n",
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=azure_storage_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexer\n",
    "Create Indexer to store logs, indexing process, and schedule indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " index-name-pull-method-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerImageAction\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "\n",
    "indexer_parameters = IndexingParameters(\n",
    "    configuration=IndexingParametersConfiguration(\n",
    "        image_action=BlobIndexerImageAction.GENERATE_NORMALIZED_IMAGE_PER_PAGE,\n",
    "        query_timeout=None))\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")],\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
